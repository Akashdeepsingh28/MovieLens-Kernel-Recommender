{"cells":[{"cell_type":"code","execution_count":45,"metadata":{"id":"ty3gYQgtnwFA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"89f4a0bd-2cac-4908-88d6-724edb5b12ec","executionInfo":{"status":"ok","timestamp":1744339062396,"user_tz":240,"elapsed":104,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Glocal_K' already exists and is not an empty directory.\n"]}],"source":["#!git clone https://github.com/usydnlp/Glocal_K.git"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"nl2tU6kL8Ot3","executionInfo":{"status":"ok","timestamp":1744339455779,"user_tz":240,"elapsed":4,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["from time import time\n","from scipy.sparse import csc_matrix\n","import numpy as np\n","import h5py\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.parameter import Parameter\n","\n","torch.manual_seed(1284)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"k4A9uU1WloQ2"},"source":["# Data Loader Function"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"cq3KEUaVo1o3","executionInfo":{"status":"ok","timestamp":1744340933602,"user_tz":240,"elapsed":42,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","def load_data_1M(path='/content/Glocal_K/data/MovieLens_1M/'):\n","    train_file = path + 'train_dataset.dat'\n","    test_file = path + 'test_dataset.dat'\n","\n","    # Load train and test using pandas\n","    train = pd.read_csv(train_file, sep='::', engine='python', header=None).iloc[:, :3].values.astype('int32')\n","    test = pd.read_csv(test_file, sep='::', engine='python', header=None).iloc[:, :3].values.astype('int32')\n","\n","    total = np.concatenate((train, test), axis=0)\n","\n","    # Create unique user and movie ID mappings\n","    unique_users = np.unique(total[:, 0])\n","    unique_movies = np.unique(total[:, 1])\n","\n","    user_id_map = {id_: idx for idx, id_ in enumerate(unique_users)}\n","    movie_id_map = {id_: idx for idx, id_ in enumerate(unique_movies)}\n","\n","    n_u = len(user_id_map)\n","    n_m = len(movie_id_map)\n","    n_train = train.shape[0]\n","    n_test = test.shape[0]\n","\n","    # Initialize rating matrices\n","    train_r = np.zeros((n_m, n_u), dtype='float32')\n","    test_r = np.zeros((n_m, n_u), dtype='float32')\n","\n","    for i in range(n_train):\n","        u_idx = user_id_map[train[i, 0]]\n","        m_idx = movie_id_map[train[i, 1]]\n","        train_r[m_idx, u_idx] = train[i, 2]\n","\n","    for i in range(n_test):\n","        u_idx = user_id_map[test[i, 0]]\n","        m_idx = movie_id_map[test[i, 1]]\n","        test_r[m_idx, u_idx] = test[i, 2]\n","\n","    train_m = (train_r > 1e-12).astype('float32')\n","    test_m = (test_r > 1e-12).astype('float32')\n","\n","    print('âœ… MovieLens 1M data loaded successfully (with ID mapping)')\n","    print(f'ðŸ‘¤ Number of unique users: {n_u}')\n","    print(f'ðŸŽ¬ Number of unique movies: {n_m}')\n","    print(f'ðŸ“Š Training ratings: {n_train}')\n","    print(f'ðŸ§ª Test ratings: {n_test}')\n","\n","    return n_m, n_u, train_r, train_m, test_r, test_m\n"]},{"cell_type":"markdown","metadata":{"id":"E_8kEkg9mlIW"},"source":["# Load Data"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"0fkA1WpmipzF","executionInfo":{"status":"ok","timestamp":1744340464594,"user_tz":240,"elapsed":5,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n","# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","data_path = '/content/Glocal_K/data/MovieLens_1M'\n","# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJqSSY33mgkw","outputId":"c5e81546-a72d-42dc-885e-7cde46926cbc","executionInfo":{"status":"ok","timestamp":1744340949189,"user_tz":240,"elapsed":8138,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… MovieLens 1M data loaded successfully (with ID mapping)\n","ðŸ‘¤ Number of unique users: 6040\n","ðŸŽ¬ Number of unique movies: 3706\n","ðŸ“Š Training ratings: 800167\n","ðŸ§ª Test ratings: 200042\n"]}],"source":["n_m, n_u, train_r, train_m, test_r, test_m = load_data_1M()\n"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"nGCdp_FlobOK","executionInfo":{"status":"ok","timestamp":1744351618694,"user_tz":240,"elapsed":4,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["# Common hyperparameter settings\n","n_hid = 500 # size of hidden layers\n","n_dim = 5 # inner AE embedding size\n","n_layers = 2 # number of hidden layers\n","gk_size = 3 # width=height of kernel for convolution\n","\n","# Hyperparameters to tune for specific case\n","max_epoch_p = 300 # max number of epochs for pretraining\n","max_epoch_f = 200 # max number of epochs for finetuning\n","patience_p = 5 # number of consecutive rounds of early stopping condition before actual stop for pretraining\n","patience_f = 3 # and finetuning\n","tol_p = 1e-3 # minimum threshold for the difference between consecutive values of train rmse, used for early stopping, for pretraining\n","tol_f = 1e-2 # and finetuning\n","lambda_2 = 20. # regularisation of number or parameters\n","lambda_s = 0.006 # regularisation of sparsity of the final matrix\n","dot_scale = 1 # dot product weight for global kernel"]},{"cell_type":"markdown","metadata":{"id":"5sWtU4-pmDDT"},"source":["# Network Functions"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"p1P6fgYiy28F","executionInfo":{"status":"ok","timestamp":1744351619992,"user_tz":240,"elapsed":23,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["def local_kernel(u, v):\n","    dist = torch.norm(u - v, p=2, dim=2)\n","    hat = torch.clamp(1. - dist**2, min=0.)\n","    return hat\n","\n","class KernelLayer(nn.Module):\n","    def __init__(self, n_in, n_hid, n_dim, lambda_s, lambda_2, activation=nn.Sigmoid()):\n","      super().__init__()\n","      self.W = nn.Parameter(torch.randn(n_in, n_hid))\n","      self.u = nn.Parameter(torch.randn(n_in, 1, n_dim))\n","      self.v = nn.Parameter(torch.randn(1, n_hid, n_dim))\n","      self.b = nn.Parameter(torch.randn(n_hid))\n","\n","      self.lambda_s = lambda_s\n","      self.lambda_2 = lambda_2\n","\n","      nn.init.xavier_uniform_(self.W, gain=torch.nn.init.calculate_gain(\"relu\"))\n","      nn.init.xavier_uniform_(self.u, gain=torch.nn.init.calculate_gain(\"relu\"))\n","      nn.init.xavier_uniform_(self.v, gain=torch.nn.init.calculate_gain(\"relu\"))\n","      nn.init.zeros_(self.b)\n","      self.activation = activation\n","\n","    def forward(self, x):\n","      w_hat = local_kernel(self.u, self.v)\n","\n","      sparse_reg = torch.nn.functional.mse_loss(w_hat, torch.zeros_like(w_hat))\n","      sparse_reg_term = self.lambda_s * sparse_reg\n","\n","      l2_reg = torch.nn.functional.mse_loss(self.W, torch.zeros_like(self.W))\n","      l2_reg_term = self.lambda_2 * l2_reg\n","\n","      W_eff = self.W * w_hat  # Local kernelised weight matrix\n","      y = torch.matmul(x, W_eff) + self.b\n","      y = self.activation(y)\n","\n","      return y, sparse_reg_term + l2_reg_term\n","\n","class KernelNet(nn.Module):\n","    def __init__(self, n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2):\n","      super().__init__()\n","      layers = []\n","      for i in range(n_layers):\n","        if i == 0:\n","          layers.append(KernelLayer(n_u, n_hid, n_dim, lambda_s, lambda_2))\n","        else:\n","          layers.append(KernelLayer(n_hid, n_hid, n_dim, lambda_s, lambda_2))\n","      layers.append(KernelLayer(n_hid, n_u, n_dim, lambda_s, lambda_2, activation=nn.Identity()))\n","      self.layers = nn.ModuleList(layers)\n","      self.dropout = nn.Dropout(0.33)\n","\n","    def forward(self, x):\n","      total_reg = None\n","      for i, layer in enumerate(self.layers):\n","        x, reg = layer(x)\n","        if i < len(self.layers)-1:\n","          x = self.dropout(x)\n","        if total_reg is None:\n","          total_reg = reg\n","        else:\n","          total_reg += reg\n","      return x, total_reg"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"7RGKh1ckXgtP","executionInfo":{"status":"ok","timestamp":1744351620354,"user_tz":240,"elapsed":3,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["class CompleteNet(nn.Module):\n","    def __init__(self, kernel_net, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale):\n","      super().__init__()\n","      self.gk_size = gk_size\n","      self.dot_scale = dot_scale\n","      self.local_kernel_net = kernel_net\n","      self.conv_kernel = torch.nn.Parameter(torch.randn(n_m, gk_size**2) * 0.1)\n","      nn.init.xavier_uniform_(self.conv_kernel, gain=torch.nn.init.calculate_gain(\"relu\"))\n","\n","\n","    def forward(self, x, x_local):\n","      gk = self.global_kernel(x_local, self.gk_size, self.dot_scale)\n","      x = self.global_conv(x, gk)\n","      x, global_reg_loss = self.local_kernel_net(x)\n","      return x, global_reg_loss\n","\n","    def global_kernel(self, input, gk_size, dot_scale):\n","      avg_pooling = torch.mean(input, dim=1)  # Item (axis=1) based average pooling\n","      avg_pooling = avg_pooling.view(1, -1)\n","\n","      gk = torch.matmul(avg_pooling, self.conv_kernel) * dot_scale  # Scaled dot product\n","      gk = gk.view(1, 1, gk_size, gk_size)\n","\n","      return gk\n","\n","    def global_conv(self, input, W):\n","      input = input.unsqueeze(0).unsqueeze(0)\n","      conv2d = nn.LeakyReLU()(F.conv2d(input, W, stride=1, padding=1))\n","      return conv2d.squeeze(0).squeeze(0)\n","\n","class Loss(nn.Module):\n","    def forward(self, pred_p, reg_loss, train_m, train_r):\n","      # L2 loss\n","      diff = train_m * (train_r - pred_p)\n","      sqE = torch.nn.functional.mse_loss(diff, torch.zeros_like(diff))\n","      loss_p = sqE + reg_loss\n","      return loss_p"]},{"cell_type":"markdown","metadata":{"id":"f8sQCwrSmKG4"},"source":["# Network Instantiation"]},{"cell_type":"markdown","metadata":{"id":"zOtWj1SCo1RW"},"source":["## Pre-training"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"7teUrgWagpW0","executionInfo":{"status":"ok","timestamp":1744351621644,"user_tz":240,"elapsed":107,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["model = KernelNet(n_u, n_hid, n_dim, n_layers, lambda_s, lambda_2).double().to(device)"]},{"cell_type":"markdown","metadata":{"id":"4IEBsNhNo4Cj"},"source":["## Fine-tuning"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"OiTXqnN6zLXQ","executionInfo":{"status":"ok","timestamp":1744351622299,"user_tz":240,"elapsed":4,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["complete_model = CompleteNet(model, n_u, n_m, n_hid, n_dim, n_layers, lambda_s, lambda_2, gk_size, dot_scale).double().to(device)"]},{"cell_type":"markdown","metadata":{"id":"sETwz58aK6y6"},"source":["# Evaluation code"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"vyReXxgac3KH","executionInfo":{"status":"ok","timestamp":1744351623061,"user_tz":240,"elapsed":7,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["def dcg_k(score_label, k):\n","    dcg, i = 0., 0\n","    for s in score_label:\n","        if i < k:\n","            dcg += (2**s[1]-1) / np.log2(2+i)\n","            i += 1\n","    return dcg"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"jwsSR-8ZdGWo","executionInfo":{"status":"ok","timestamp":1744351623306,"user_tz":240,"elapsed":18,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["def ndcg_k(y_hat, y, k):\n","    score_label = np.stack([y_hat, y], axis=1).tolist()\n","    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n","    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n","    norm, i = 0., 0\n","    for s in score_label_:\n","        if i < k:\n","            norm += (2**s[1]-1) / np.log2(2+i)\n","            i += 1\n","    dcg = dcg_k(score_label, k)\n","    return dcg / norm"]},{"cell_type":"code","execution_count":95,"metadata":{"id":"yy9eQS51pbhj","executionInfo":{"status":"ok","timestamp":1744351623487,"user_tz":240,"elapsed":3,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[],"source":["def call_ndcg(y_hat, y):\n","    ndcg_sum, num = 0, 0\n","    y_hat, y = y_hat.T, y.T\n","    n_users = y.shape[0]\n","\n","    for i in range(n_users):\n","        y_hat_i = y_hat[i][np.where(y[i])]\n","        y_i = y[i][np.where(y[i])]\n","\n","        if y_i.shape[0] < 2:\n","            continue\n","\n","        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n","        num += 1\n","\n","    return ndcg_sum / num"]},{"cell_type":"markdown","metadata":{"id":"RXXQjeMxmYEC"},"source":["# Training and Test Loop"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ35Zoha-Eue","outputId":"058dba33-b7a7-4701-c5f4-9be7a76b76a3","executionInfo":{"status":"ok","timestamp":1744351757385,"user_tz":240,"elapsed":133579,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[{"output_type":"stream","name":"stdout","text":[".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","PRE-TRAINING\n","Epoch: 0 test rmse: 2.8141057 train rmse: 2.811838\n","Time: 8.149318933486938 seconds\n","Time cumulative: 8.149318933486938 seconds\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","PRE-TRAINING\n","Epoch: 14 test rmse: 1.5162538 train rmse: 1.5109999\n","Time: 130.45675778388977 seconds\n","Time cumulative: 975.6936945915222 seconds\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"]}],"source":["best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n","best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n","\n","time_cumulative = 0\n","tic = time()\n","\n","# Pre-Training\n","optimizer = torch.optim.AdamW(complete_model.local_kernel_net.parameters(), lr=0.001)\n","\n","def closure():\n","  optimizer.zero_grad()\n","  x = torch.Tensor(train_r).double().to(device)\n","  m = torch.Tensor(train_m).double().to(device)\n","  complete_model.local_kernel_net.train()\n","  pred, reg = complete_model.local_kernel_net(x)\n","  loss = Loss().to(device)(pred, reg, m, x)\n","  loss.backward()\n","  return loss\n","\n","last_rmse = np.inf\n","counter = 0\n","\n","for i in range(max_epoch_p):\n","  optimizer.step(closure)\n","  complete_model.local_kernel_net.eval()\n","  t = time() - tic\n","  time_cumulative += t\n","\n","  pre, _ = model(torch.Tensor(train_r).double().to(device))\n","\n","  pre = pre.float().cpu().detach().numpy()\n","\n","  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n","  test_rmse = np.sqrt(error)\n","\n","  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n","  train_rmse = np.sqrt(error_train)\n","\n","  if last_rmse-train_rmse < tol_p:\n","    counter += 1\n","  else:\n","    counter = 0\n","\n","  last_rmse = train_rmse\n","\n","  if patience_p == counter:\n","    print('.-^-._' * 12)\n","    print('PRE-TRAINING')\n","    print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n","    print('Time:', t, 'seconds')\n","    print('Time cumulative:', time_cumulative, 'seconds')\n","    print('.-^-._' * 12)\n","    break\n","\n","\n","  if i % 50 != 0:\n","    continue\n","  print('.-^-._' * 12)\n","  print('PRE-TRAINING')\n","  print('Epoch:', i, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n","  print('Time:', t, 'seconds')\n","  print('Time cumulative:', time_cumulative, 'seconds')\n","  print('.-^-._' * 12)"]},{"cell_type":"code","source":["# Fine-Tuning\n","\n","train_r_local = np.clip(pre, 1., 5.)\n","\n","optimizer = torch.optim.AdamW(complete_model.parameters(), lr=0.001)\n","\n","def closure():\n","  optimizer.zero_grad()\n","  x = torch.Tensor(train_r).double().to(device)\n","  x_local = torch.Tensor(train_r_local).double().to(device)\n","  m = torch.Tensor(train_m).double().to(device)\n","  complete_model.train()\n","  pred, reg = complete_model(x, x_local)\n","  loss = Loss().to(device)(pred, reg, m, x)\n","  loss.backward()\n","  return loss\n","\n","last_rmse = np.inf\n","counter = 0\n","\n","for i in range(max_epoch_f):\n","  optimizer.step(closure)\n","  complete_model.eval()\n","  t = time() - tic\n","  time_cumulative += t\n","\n","  pre, _ = complete_model(torch.Tensor(train_r).double().to(device), torch.Tensor(train_r_local).double().to(device))\n","\n","  pre = pre.float().cpu().detach().numpy()\n","\n","  error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n","  test_rmse = np.sqrt(error)\n","\n","  error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n","  train_rmse = np.sqrt(error_train)\n","\n","  test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n","  train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n","\n","  test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n","  train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n","\n","  if test_rmse < best_rmse:\n","      best_rmse = test_rmse\n","      best_rmse_ep = i+1\n","\n","  if test_mae < best_mae:\n","      best_mae = test_mae\n","      best_mae_ep = i+1\n","\n","  if best_ndcg < test_ndcg:\n","      best_ndcg = test_ndcg\n","      best_ndcg_ep = i+1\n","\n","  if last_rmse-train_rmse < tol_f:\n","    counter += 1\n","  else:\n","    counter = 0\n","\n","  last_rmse = train_rmse\n","\n","  if patience_f == counter:\n","    print('.-^-._' * 12)\n","    print('FINE-TUNING')\n","    print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n","    print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n","    print('Time:', t, 'seconds')\n","    print('Time cumulative:', time_cumulative, 'seconds')\n","    print('.-^-._' * 12)\n","    break\n","\n","\n","  if i % 50 != 0:\n","    continue\n","\n","  print('.-^-._' * 12)\n","  print('FINE-TUNING')\n","  print('Epoch:', i, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n","  print('Epoch:', i, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n","  print('Time:', t, 'seconds')\n","  print('Time cumulative:', time_cumulative, 'seconds')\n","  print('.-^-._' * 12)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6v_tODcweLn","outputId":"b4cd4ec7-7c24-46f4-d652-10edee84c852","executionInfo":{"status":"ok","timestamp":1744351940153,"user_tz":240,"elapsed":182769,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":[".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","FINE-TUNING\n","Epoch: 0 test rmse: 1.2621422 test mae: 1.0589802 test ndcg: 0.789556135781861\n","Epoch: 0 train rmse: 1.2535967 train mae: 1.0516102 train ndcg: 0.7968106072050845\n","Time: 145.46103620529175 seconds\n","Time cumulative: 1121.154730796814 seconds\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n","FINE-TUNING\n","Epoch: 8 test rmse: 1.0393575 test mae: 0.8323624 test ndcg: 0.8470275394323381\n","Epoch: 8 train rmse: 1.0251895 train mae: 0.8197327 train ndcg: 0.8573149179737679\n","Time: 304.1809709072113 seconds\n","Time cumulative: 2774.033831357956 seconds\n",".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n"]}]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTi_PdXJqTjh","outputId":"e5858e69-72f5-4308-c159-ffb45a472dfe","executionInfo":{"status":"ok","timestamp":1744351940155,"user_tz":240,"elapsed":14,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 8  best rmse: 1.0393575\n","Epoch: 6  best mae: 0.82948416\n","Epoch: 8  best ndcg: 0.8470275394323381\n"]}],"source":["# Final result\n","print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n","print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n","print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"]},{"cell_type":"code","source":[],"metadata":{"id":"b6Yfh3hm4Efa","executionInfo":{"status":"ok","timestamp":1744351940155,"user_tz":240,"elapsed":3,"user":{"displayName":"Akash deep singh","userId":"14762307519789049521"}}},"execution_count":98,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}